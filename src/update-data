#!/usr/bin/env sh

DATASET=$1

export PYTHONPATH=${PYTHONPATH}:/srv/map-portal/usr/lib/python2.6/site-packages/
export PATH=${PATH}:/srv/map-portal/usr/bin/

# configuration

case $DATASET in

    ww3)
        SERVER=http://opendap.bom.gov.au:8080/
        SERVER_PATH=thredds/fileServer/nmoc/ww3_global_fc/
        DATA_SUBDIR=forecast
        ;;
    oceanmaps)
        SERVER=http://opendap.bom.gov.au:8080/
        SERVER_PATH=thredds/fileServer/nmoc/oceanmaps_ofam_fc/ops/latest/
        DATA_SUBDIR=data
	;;
    chloro)
        SERVER=http://opendap.jpl.nasa.gov/
        SERVER_PATH=opendap/allData/modis/L3/aqua/chlA/4km/
        DATA_SUBDIR=
        ;;
    currents)
        SERVER=ftp://ftp.hycom.org
        SERVER_PATH=/datasets/GLBu0.08/expt_91.1/forecasts
        MIRROR_FLAGS='-I *GLOB_4*.nc.gz' 
        ;;
    currents)
        SERVER=ftp://ftp.hycom.org
        SERVER_PATH=/datasets/GLBu0.08/expt_91.1/forecasts
        DATA_SUBDIR=data
        MIRROR_FLAGS='-I *uv3z.nc'
        ;;
    coral)
        SERVER=ftp://ftp.star.nesdis.noaa.gov
        SERVER_PATH=/pub/sod/mecb/gliu/crw_5km_for_bom
        DATA_SUBDIR=data
        MIRROR_FLAGS='-I baa_max*.nc'
        ;;
    poama)
        SERVER=http://opendap.bom.gov.au:8080
        SERVER_PATH=thredds/fileServer/paccsap/sea_surface_temperature_seasonal/grid/
        DATA_SUBDIR=data
        ;;
    ersst)
        SERVER=ftp.ncdc.noaa.gov
        SERVER_PATH=/pub/data/cmb/ersst/v3b/netcdf/
        DATA_SUBDIR=monthly
        ;;
    reynolds)
        SERVER=eclipse.ncdc.noaa.gov
        SERVER_PATH=/pub/oisst/NetCDF/
        DATA_SUBDIR=daily-new
        MIRROR_FLAGS='-I *.nc.gz'
        ;;
    sealevel)
        BASE_URL=http://www.bom.gov.au/ntc
        DATA_SUBDIR=gauges-new
        ;;
    *)
        echo "Unknown dataset $DATASET" >&2
        exit 1
        ;;
esac

# load variables from ocean.config

DATA_DIR=`python << EOF
from ocean.config import get_server_config

config = get_server_config()
print config['dataDir']["$DATASET"]
EOF`

if [ "x$DATA_DIR" = "x" ]; then
    echo "DATA_DIR empty, very bad! Is PYTHONPATH set?" >&2
    exit 1
fi

# download data

cd $DATA_DIR/$DATA_SUBDIR || exit 1

case $DATASET in
    reynolds|ersst|coral|currents)
        lftp $SERVER << EOF
cd $SERVER_PATH || exit 1
mirror --only-missing -n $MIRROR_FLAGS
chmod -R 666
EOF
    ;;
    poama)
            FILE=PACCSAP_oa_latest.nc
            URL=$SERVER/$SERVER_PATH/$FILE
            wget - $FILE "$URL" || echo -n "error ($?)"
            echo
    ;;
    ww3)
        dates=("$(date +"%Y%m%d")" "$(date --date="yesterday" +"%Y%m%d")")
        hours=("12" "00")
        for date in "${dates[@]}"
        do
            for hour in "${hours[@]}"
            do
                FILE="$(printf "ww3_%s_%s.nc" "$date" "$hour")"
                URL=$SERVER/$SERVER_PATH/$FILE
                if [[ -e $FILE ]];
                then
                    break 2;
                else
                    wget -nc -nv "$URL";
                    if [[ $? -eq 0 ]];
                    then
                        break 2;
                    else
                        continue; 
                    fi
                fi
            done
        done
        response=`python << EOF
import urllib
import urllib2
import time
url = "http://tunceli/portal/cgi/portal.py"
values = {"dataset": "ww3forecast",
          "variable": "sig_wav_ht",
          "plot": "map",
          "period": "7days",
          "area": "pac",
          "mode": "preprocess"
           }
data = urllib.urlencode(values)
full_url = url + '?' + data
try:
    response = urllib2.urlopen(full_url)
    print response.read()
except urllib2.HTTPError as e:
    print e.read()

url = "http://www.bom.gov.au/cosppac/apps/portal/cgi/portal.py"
full_url = url + '?' + data
try:
    response = urllib2.urlopen(full_url)
    print response.read()
except urllib2.HTTPError as e:
    print e.read()
EOF`
        echo -n $response
    ;;
    chloro)
        response=`python << EOF
import os
import urllib
import urllib2
from datetime import datetime, timedelta
from subprocess import check_call, CalledProcessError

url = '$SERVER/$SERVER_PATH'
OneM = 1000000
#daily
today = datetime.now()
for delta in range(4):
    date = today + timedelta(-delta)
    date = date.timetuple()
    file_name = 'A%4d%03d.L3m_DAY_CHL_chlor_a_4km.bz2' % (date.tm_year, date.tm_yday)
    file_path = 'daily/' + file_name
    full_url = '%sdaily/%4d/%03d/%s' % (url, date.tm_year, date.tm_yday, file_name)
    if os.path.exists(file_path):
        continue
    else:
        try:
           mega = urllib2.urlopen(full_url)
           file, msg = urllib.urlretrieve(full_url, file_path)
           urllib.urlcleanup()
           print file
           check_call(['h4tonccf_nc4', file_path])
           os.remove(file_path)
        except urllib2.HTTPError as e:
            print e.read()
            print '\n'
            continue
        except CalledProcessError as cpe:
            print cpe.read()
#monthly
EOF`
        echo -n $response
    ;;
    sealevel)
        python << EOF | while read PRODUCT GAUGE
from ocean.config.tidalGaugeConfig import tidalGauge

for gauge in tidalGauge:
    product = gauge.split('_')[0]
    print product, gauge

EOF
        do
            echo -n "$GAUGE: "
            FILE=${GAUGE}SLD.txt
            URL=$BASE_URL/$PRODUCT/$FILE
            echo -n "$URL "
            wget -qO $FILE $URL || echo -n "error ($?)"
            echo
        done
    ;;

esac

# processing

case $DATASET in
    reynolds)
        python << EOF
# recompress daily data
from ocean.processing.uncompress_synched_data import uncompress_synched_data

uncompress_synched_data().process("$DATASET")
print "Calculate Monthly Averages..."

# calculate monthly averages
from ocean.processing.Calculate_Monthly_Averages import Calculate_Monthly_Averages

Calculate_Monthly_Averages().process("$DATASET")

EOF

    ;& # continue

    ersst)
        python << EOF
# apply a patch to ERSST files
from ocean.processing.convert_ERSST_files import convert
convert()

# calculate multi month averages
from ocean.processing.Calculate_MultiMonth_Averages import Calculate_MultiMonth_Averages

Calculate_MultiMonth_Averages().process("$DATASET")

# FIXME: calculate deciles
EOF
    ;;
    coral)
find ./ -name "*.hdf" -exec h4toh5 {} \;
find ./ -name "*.*" -exec chmod 777 {} \;
    ;;
esac
