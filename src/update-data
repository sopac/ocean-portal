#!/usr/bin/env sh

DATASET=$1
PERIOD=$2

export PYTHONPATH=${PYTHONPATH}:/srv/map-portal/usr/lib/python2.6/site-packages/:/srv/map-portal/usr/lib64/python2.6/site-packages
export PATH=${PATH}:/srv/map-portal/usr/bin/
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/srv/map-portal/usr/lib/

# configuration

case $DATASET in

    ww3)
        SERVER=http://opendap.bom.gov.au:8080/
        SERVER_PATH=thredds/fileServer/nmoc/ww3_global_fc/
        DATA_SUBDIR=forecast
        ;;
    oceanmaps)
        SERVER=http://opendap.bom.gov.au:8080/
        SERVER_PATH=thredds/fileServer/nmoc/oceanmaps_ofam_fc/ops/latest/
        DATA_SUBDIR=data
	;;
    chloro)
        SERVER=http://oceandata.sci.gsfc.nasa.gov
        SERVER_PATH=cgi/getfile/
        DATA_SUBDIR=
        ;;
    currents)
        SERVER=http://tds.hycom.org/
        SERVER_PATH=/thredds/dodsC/GLBu0.08/expt_91.1/forecasts
        DATA_SUBDIR=daily
        ;;
    coral)
        SERVER=ftp://ftp.star.nesdis.noaa.gov
        SERVER_PATH=/pub/sod/mecb/crw/data/5km/nc/baa_max_comp_7day
        DATA_SUBDIR=daily
        MIRROR_FLAGS='-I baa_max*.nc'
        ;;
    coral_ol)
        SERVER=ftp://ftp.star.nesdis.noaa.gov
        SERVER_PATH=/pub/sod/mecb/gliu/outlook_for_bom_v3
        DATA_SUBDIR=outlook
        MIRROR_FLAGS='-I outlook*.dat'
        ;;
    msla)
        SERVER=ftp://ftp.aviso.altimetry.fr
        SERVER_PATH=/global/near-real-time/grids/msla/all-sat-merged/
        DATA_SUBDIR=h
        ;;
    poamasla)
        SERVER=http://opendap.bom.gov.au:8080
        SERVER_PATH=/thredds/fileServer/paccsap/sea_level_seasonal/grid/
        DATA_SUBDIR=sla
        ;;
    poamassta)
        SERVER=http://opendap.bom.gov.au:8080
        SERVER_PATH=/thredds/fileServer/paccsap/sea_surface_temperature_seasonal/grid/
        DATA_SUBDIR=ssta
        ;;
    ersst)
        SERVER=ftp.ncdc.noaa.gov
        SERVER_PATH=/pub/data/cmb/ersst/v3b/netcdf/
        DATA_SUBDIR=monthly
        ;;
    reynolds)
        SERVER=eclipse.ncdc.noaa.gov
        SERVER_PATH=/pub/oisst/NetCDF/
        DATA_SUBDIR=daily-new
        MIRROR_FLAGS='-I *.nc.gz'
        ;;
    decile)
        SERVER=d
        SERVER_PATH=e
        DATA_SUBDIR=c
        ;;
    sealevel)
        BASE_URL=http://www.bom.gov.au/ntc
        DATA_SUBDIR=gauges-new
        ;;
    mur)
	SERVER=http://podaac-opendap.jpl.nasa.gov
	SERVER_PATH=/opendap/allData/ghrsst/data/L4/GLOB/JPL/MUR/
	DATA_SUBDIR=data
	;;
    *)
        echo "Unknown dataset $DATASET" >&2
        exit 1
        ;;
esac

# load variables from ocean.config

if [ "$DATASET" != "decile" ]; then

DATA_DIR=`python << EOF
from ocean.config import get_server_config

config = get_server_config()
print config['dataDir']["$DATASET"]
EOF`

if [ "x$DATA_DIR" = "x" ]; then
    echo "DATA_DIR empty, very bad! Is PYTHONPATH set?" >&2
    exit 1
fi

# download data

cd $DATA_DIR$DATA_SUBDIR || exit 1
fi

case $DATASET in
    reynolds|ersst|coral|coral_ol)
        lftp $SERVER << EOF
cd $SERVER_PATH || exit 1
mirror --only-missing -n $MIRROR_FLAGS
chmod -R 666
EOF
    ;;
    poamasla)
            FILE='sla_grid_latest.nc'
            URL=$SERVER/$SERVER_PATH/$FILE
            wget -q "$URL" -O "$FILE"|| echo -n "error ($?)"
            response=`python << EOF
import os
from subprocess import check_call, CalledProcessError
try:
    check_call(['ncatted', '-a', '_FillValue,HEIGHT,c,f,NaN', '$FILE'])
except CalledProcessError as cpe:
    print cpe.read()
    print '\n'
"""
pre-generate configuration file and images.
"""
import urllib
import urllib2
#----------preprocess on tunceli--------
url = "http://tunceli/portal/cgi/portal.py"
values = {"dataset": "poamasla",
          "variable": "height",
          "plot": "map",
          "period": "seasonal",
          "area": "pac",
          "date": "20120701",
          "mode": "preprocess"
           }
data = urllib.urlencode(values)
full_url = url + '?' + data
try:
    response = urllib2.urlopen(full_url)
    print response.read()
except urllib2.HTTPError as e:
    print e.read()
#----------preprocess on www--------
url = "http://www.bom.gov.au/cosppac/apps/portal/cgi/portal.py"
full_url = url + '?' + data
try:
    response = urllib2.urlopen(full_url)
    print response.read()
except urllib2.HTTPError as e:
    print e.read()

EOF`
            echo -n $response
    ;;
    poamassta)
            FILE='PACCSAP_oa_latest.nc'
            URL=$SERVER/$SERVER_PATH/$FILE
            wget -q "$URL" -O "$FILE" || echo -n "error ($?)"
            response=`python << EOF
import os
from subprocess import check_call, CalledProcessError
try:
    check_call(['ncatted', '-a', '_FillValue,SSTA,c,f,-999', '$FILE'])
except CalledProcessError as cpe:
    print cpe.read()
    print '\n'
"""
pre-generate configuration file and images.
"""
import urllib
import urllib2

#----------preprocess on tunceli--------
url = "http://tunceli/portal/cgi/portal.py"
values = {"dataset": "poamassta",
          "variable": "ssta",
          "plot": "map",
          "period": "seasonal",
          "area": "pac",
          "date": "20120701",
          "mode": "preprocess"
           }
data = urllib.urlencode(values)
full_url = url + '?' + data
try:
    response = urllib2.urlopen(full_url)
    print response.read()
except urllib2.HTTPError as e:
    print e.read()

values = {"dataset": "poamassta",
          "variable": "sst",
          "plot": "map",
          "period": "seasonal",
          "area": "pac",
          "date": "20120701",
          "mode": "preprocess"
           }
data = urllib.urlencode(values)
full_url = url + '?' + data
try:
    response = urllib2.urlopen(full_url)
    print response.read()
except urllib2.HTTPError as e:
    print e.read()

#----------preprocess on www--------
url = "http://www.bom.gov.au/cosppac/apps/portal/cgi/portal.py"
values = {"dataset": "poamassta",
          "variable": "ssta",
          "plot": "map",
          "period": "seasonal",
          "area": "pac",
          "date": "20120701",
          "mode": "preprocess"
           }
data = urllib.urlencode(values)
full_url = url + '?' + data
try:
    response = urllib2.urlopen(full_url)
    print response.read()
except urllib2.HTTPError as e:
    print e.read()

values = {"dataset": "poamassta",
          "variable": "sst",
          "plot": "map",
          "period": "seasonal",
          "area": "pac",
          "date": "20120701",
          "mode": "preprocess"
           }
data = urllib.urlencode(values)
full_url = url + '?' + data
try:
    response = urllib2.urlopen(full_url)
    print response.read()
except urllib2.HTTPError as e:
    print e.read()

EOF`
            echo -n $response
    ;;
    ww3)
        dates=("$(date +"%Y%m%d")" "$(date --date="yesterday" +"%Y%m%d")")
        hours=("12" "00")
        for date in "${dates[@]}"
        do
            for hour in "${hours[@]}"
            do
                FILE="$(printf "ww3_%s_%s.nc" "$date" "$hour")"
                URL=$SERVER/$SERVER_PATH/$FILE
                if [[ -e $FILE ]];
                then
                    break 2;
                else
                    wget -nc -nv "$URL";
                    if [[ $? -eq 0 ]];
                    then
                        break 2;
                    else
                        continue; 
                    fi
                fi
            done
        done
        response=`python << EOF
import urllib
import urllib2
import time
#-------batch process on tunceli-----
url = "http://tunceli/portal/cgi/portal.py"
values = {"dataset": "ww3forecast",
          "variable": "sig_wav_ht",
          "plot": "map",
          "period": "7days",
          "area": "pac",
          "mode": "preprocess"
           }
data = urllib.urlencode(values)
full_url = url + '?' + data
try:
    response = urllib2.urlopen(full_url)
    print response.read()
except urllib2.HTTPError as e:
    print e.read()

#-------batch process on www-----
url = "http://www.bom.gov.au/cosppac/apps/portal/cgi/portal.py"
full_url = url + '?' + data
try:
    response = urllib2.urlopen(full_url)
    print response.read()
except urllib2.HTTPError as e:
    print e.read()

EOF`
        echo -n $response
    ;;
    chloro)
        response=`python << EOF
import os
import urllib
import urllib2
from datetime import timedelta, date
from subprocess import check_call, CalledProcessError
import calendar

url = '$SERVER/$SERVER_PATH'
today = date.today()
#daily
if '$PERIOD' == 'daily':
    for delta in range(4):
        date = today + timedelta(-delta)
        date = date.timetuple()
        file_name = 'A%4d%03d.L3m_DAY_CHL_chlor_a_4km' % (date.tm_year, date.tm_yday)
        nc_file_name = file_name + '.nc'
        nc_file_path = 'daily/' + nc_file_name
        full_url = url + nc_file_name
        if os.path.exists(nc_file_path):
            continue
        else:
            try:
               mega = urllib2.urlopen(full_url)
               file, msg = urllib.urlretrieve(full_url, nc_file_path)
               urllib.urlcleanup()
               print file
            except urllib2.URLError as e:
                print e.strerror
                print '\n'
                continue
            except urllib2.HTTPError as e:
                print e.read()
                print '\n'
                continue
#monthly
elif '$PERIOD' == 'monthly':
    date = today.replace(day=1)
    for delta in range(2):
        date = date + timedelta(-1)
        first_day_month = date.replace(day=1)
        last_day_month = date.replace(day=calendar.monthrange(date.year, date.month)[1])
        date = first_day_month

        first_date = first_day_month.timetuple()
        last_date = last_day_month.timetuple() 
        file_name = 'A%4d%03d%4d%03d.L3m_MO_CHL_chlor_a_4km' % (first_date.tm_year, first_date.tm_yday, last_date.tm_year, last_date.tm_yday)
        nc_file_name = file_name + '.nc'
        nc_file_path = 'monthly/' + nc_file_name
        full_url = url + nc_file_name
        if os.path.exists(nc_file_path):
            continue
        else:
            try:
               mega = urllib2.urlopen(full_url)
               file, msg = urllib.urlretrieve(full_url, nc_file_path)
               urllib.urlcleanup()
               print file
            except urllib2.URLError as e:
                print e.strerror
                print '\n'
                continue
            except urllib2.HTTPError as e:
                print e.read()
                print '\n'
                continue
EOF`
        echo -n $response
    ;;
    sealevel)
        python << EOF | while read PRODUCT GAUGE
from ocean.config.tidalGaugeConfig import tidalGauge

for gauge in tidalGauge:
    product = gauge.split('_')[0]
    print product, gauge

EOF
        do
            echo -n "$GAUGE: "
            FILE=${GAUGE}SLD.txt
            URL=$BASE_URL/$PRODUCT/$FILE
            echo -n "$URL "
            wget -qO $FILE $URL || echo -n "error ($?)"
            echo
        done
    ;;

esac

# processing

case $DATASET in
    reynolds)
        python << EOF
# recompress daily data
from ocean.processing.uncompress_synched_data import uncompress_synched_data

uncompress_synched_data().process("$DATASET")
print "Calculate Monthly Averages..."

# calculate monthly averages
from ocean.processing.Calculate_Monthly_Averages import Calculate_Monthly_Averages

Calculate_Monthly_Averages().process("$DATASET")

EOF

    ;& # continue

    ersst)
        python << EOF
# apply a patch to ERSST files
from ocean.processing.convert_ERSST_files import convert
convert()

# calculate multi month averages
from ocean.processing.Calculate_MultiMonth_Averages import Calculate_MultiMonth_Averages

Calculate_MultiMonth_Averages().process("$DATASET")

# FIXME: calculate deciles
EOF
    ;;

    coral_ol)
        python << EOF
print "Convert CRW Outlook V3 to NETCDF..."

from ocean.processing.Convert_Coral_Outlook import Convert_Outlook

Convert_Outlook("$DATA_DIR","$DATA_SUBDIR")

EOF
    ;;

    currents)
        python << EOF
print "Download and Convert HYCOM Currents..."

from ocean.processing.Download_Compile_HYCOM_Currents import Download_Compile_HYCOM_Currents

Download_Compile_HYCOM_Currents("$DATA_DIR","$DATA_SUBDIR","$SERVER","$SERVER_PATH")

import urllib
import urllib2
from ocean.config import regionConfig
#-------------preprocess on tunceli--------
url = "http://tunceli/portal/cgi/portal.py"
values = {"dataset": "currentforecast",
          "variable": "currents",
          "plot": "map",
          "period": "3days",
          "area": "fiji",
          "date": "20120701",
          "mode": "preprocess"
         }
data = urllib.urlencode(values)
full_url = url + '?' + data
try:
    response = urllib2.urlopen(full_url, None, 60000)
    print response.read()
except urllib2.HTTPError as e:
    print e.read()

#-------------preprocess on www--------
url = "http://www.bom.gov.au/cosppac/apps/portal/cgi/portal.py"
full_url = url + '?' + data
try:
    response = urllib2.urlopen(full_url, None, 60000)
    print response.read()
except urllib2.HTTPError as e:
    print e.read()

EOF
    ;;

    mur)
	python << EOF
print "Download MUR and process fronts..."

from ocean.processing.Download_MUR import Download_MUR
Download_MUR("$DATA_DIR","$DATA_SUBDIR","$SERVER","$SERVER_PATH")
EOF
    ;;

    decile)
        python << EOF
print "Calculate Decile ..."

# calculate decile, currrently for Reynolds only 
from ocean.processing.Calculate_Deciles import Calculate_Deciles

Calculate_Deciles().process("reynolds")

EOF
    ;;

esac
